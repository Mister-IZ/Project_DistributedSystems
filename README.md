# üìö Documentation Projet Kubernetes - Distributed Systems

## üìã Table des Mati√®res
1. [Vue d'ensemble](#vue-densemble)
2. [Configuration du Cluster](#1-configuration-du-cluster)
3. [Pipeline CI/CD](#2-pipeline-cicd)
4. [Configuration de la Base de Donn√©es](#3-configuration-de-la-base-de-donn√©es)
5. [Monitoring et Scaling](#4-monitoring-et-scaling)
6. [Guide d'Onboarding](#5-guide-donboarding)

7. [---- Guide de d√©monstration de l'ensemble ----](./app/README.md)

---

## üéØ Vue d'ensemble

**Distributed Systems Demo** est une infrastructure Kubernetes professionnelle d√©montrant les concepts avanc√©s de microservices, sharding MongoDB, cache Redis et pipeline CI/CD automatis√©.

### üåê URLs d'Acc√®s
- **Environnement DEV (PROD)** : `http://demo.local`
- **Environnement TEST** : `http://test.demo.local`
- **Dashboard Kubernetes** : `http://localhost:8001` (apr√®s `kubectl proxy`)

### üèóÔ∏è Architecture Technique

**üìù NOTE IMPORTANTE : Configuration approuv√©e par l'enseignant**

*Dans le cadre de ce projet, l'environnement **DEV** fait office d'environnement **PRODUCTION**.
Cette simplification a √©t√© valid√©e pour d√©montrer l'ensemble des fonctionnalit√©s requises tout en optimisant les ressources.*

Namespace DEV (**Production**):
- üîß MongoDB Sharding Cluster (8 pods)
  - Config Servers (3 pods - replica set rs-config)
  - Shard Servers (3 pods - replica set rs-shard)
  - Mongos Routers (2 pods)
- üéØ Redis Cluster (2 pods r√©pliqu√©s)
- üöÄ Application Flask (3 pods)

Namespace TEST :
- üóÑÔ∏è MongoDB R√©plication (3 pods - replica set rs0)
- üéØ Redis (2 pods r√©pliqu√©s)
- üöÄ Application Flask (2 pods)
- ‚öôÔ∏è CronJob Auto-Update (ex√©cution toutes les 5 minutes)

### üéØ Stack Technologique
- **Application** : Flask (Python) + HTML int√©gr√©
- **Base de donn√©es** : MongoDB (sharding/r√©plication) + Redis (cache)
- **Orchestration** : Kubernetes + Docker Desktop
- **CI/CD** : GitHub Actions + Docker Hub
- **Monitoring** : Kubernetes Dashboard + Metrics Server

---

## 1. üì¶ Configuration du Cluster

### 1.1 Pr√©requis
- ‚úÖ **Docker Desktop** avec Kubernetes activ√©
- ‚úÖ **kubectl** configur√©
- ‚úÖ **Git** pour cloner le repository
- ‚úÖ **Acc√®s au fichier hosts** pour la configuration DNS locale

### 1.2 Installation - Environnement Local

#### √âtape 1 : Installation de Docker Desktop
```
# T√©l√©charger Docker Desktop
# https://www.docker.com/products/docker-desktop/

# Activer Kubernetes
# Docker Desktop ‚Üí Settings ‚Üí Kubernetes ‚Üí Enable Kubernetes

# V√©rifier l'installation
kubectl cluster-info
kubectl get nodes
```

#### √âtape 2 : Configuration DNS Locale
√âditer le fichier hosts :
- **Windows** : `C:\Windows\System32\drivers\etc\hosts`
- **Linux/Mac** : `/etc/hosts`

Ajouter les lignes suivantes :
```
127.0.0.1 demo.local
127.0.0.1 test.demo.local
```

#### √âtape 3 : Installation du Cluster (Automatis√©e)
```
git clone <repository-url>
cd Project_DistributedSystems
./start-cluster.sh
```

#### √âtape 4 : Installation Manuelle (Alternative)
```
kubectl apply -f manifests/namespaces.yaml
kubectl apply -f manifests/mongodb-config.yaml -n dev
kubectl apply -f manifests/mongodb-shard.yaml -n dev
kubectl apply -f manifests/mongodb-mongos.yaml -n dev
kubectl apply -f manifests/mongodb-test.yaml -n test
kubectl apply -f manifests/redis-dev.yaml -n dev
kubectl apply -f manifests/redis-test.yaml -n test
kubectl apply -f manifests/web-deployment.yaml -n dev
kubectl apply -f manifests/test-deployment.yaml -n test
./setup-sharding.sh
```

### 1.3 Installation Ingress Controller
```
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml
kubectl get pods -n ingress-nginx
kubectl get services -n ingress-nginx
```

### 1.4 V√©rification de l'Installation
```
kubectl get pods -A
curl -I http://demo.local
curl -I http://test.demo.local
kubectl get services -A
kubectl get ingress -A
```

### 1.5 Proc√©dure de Red√©marrage
```
./start-cluster.sh
./setup-sharding.sh
curl http://demo.local
curl http://test.demo.local
```

### 1.6 Arr√™t Propre du Cluster
```
# Docker Desktop ‚Üí Param√®tres ‚Üí Kubernetes ‚Üí Stop
# Attendre l'arr√™t complet
# Quitter Docker Desktop
```

---

## 2. üîÑ Pipeline CI/CD

### 2.1 Vue d'ensemble du Pipeline
Git Push ‚Üí Tests Unitaires ‚Üí Build Docker ‚Üí Push Docker Hub ‚Üí Auto-Deploy TEST (Apr√©s cela : Validation manuelle ‚Üí D√©ploiement PROD (DEV))

Workflow de production :

- TEST : D√©ploiement automatique apr√®s validation CI/CD
- PROD (DEV) : D√©ploiement manuel apr√®s validation des tests
- Zero-downtime garanti dans les deux environnements

### 2.2 Configuration GitHub Actions
```yaml
name: CI/CD Pipeline
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
jobs:
  build-test-deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
        env:
          PYTHONPATH: .
      - name: Run unit tests
        run: pytest -v
      - name: Build Docker image
        run: |
          docker build -t ${{ secrets.DOCKER_HUB_USERNAME }}/demo-app:latest .
          docker build -t ${{ secrets.DOCKER_HUB_USERNAME }}/demo-app:${{ github.sha }} .
      - name: Push to Docker Hub
        run: |
          echo "${{ secrets.DOCKER_HUB_ACCESS_TOKEN }}" | docker login -u "${{ secrets.DOCKER_HUB_USERNAME }}" --password-stdin
          docker push ${{ secrets.DOCKER_HUB_USERNAME }}/demo-app:latest
          docker push ${{ secrets.DOCKER_HUB_USERNAME }}/demo-app:${{ github.sha }}
```

### 2.3 Secrets GitHub Requis
- `DOCKER_HUB_USERNAME`
- `DOCKER_HUB_ACCESS_TOKEN`

### 2.4 Syst√®me d'Auto-Update TEST
```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: auto-sync-demo-app
  namespace: test
spec:
  schedule: "*/5 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: auto-sync-sa
          containers:
          - name: auto-sync
            image: alpine/k8s:1.30.8
            command:
            - /bin/sh
            - -c
            - |
              bash /scripts/check-and-update.sh
          volumeMounts:
          - name: script
            mountPath: /scripts
          volumes:
          - name: script
            configMap:
              name: auto-sync-script
```

### 2.5 Tests Unitaires
```python
import pytest
from app.app import app

@pytest.fixture
def client():
    app.testing = True
    with app.test_client() as client:
        yield client

def test_homepage(client):
    response = client.get('/')
    assert response.status_code == 200
```

### 2.6 D√©ploiement Zero Downtime
```yaml
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
```

---

## 3. üóÑÔ∏è Configuration de la Base de Donn√©es

### 3.1 Architecture MongoDB
- DEV (PROD) : Sharding avanc√© (Config Servers 3 pods, Shards 3 pods, Mongos 2 pods)
- TEST : R√©plication simple (MongoDB 3 pods)

### 3.2 Configuration du Sharding
```bash
./setup-sharding.sh
```

### 3.3 V√©rification du Sharding
```bash
kubectl exec -n dev deployment/mongo-mongos -- mongosh --eval "sh.status()"
kubectl exec -n dev deployment/mongo-mongos -- mongosh demoDB --eval "db.hosts.getShardDistribution()"
kubectl exec -n dev mongo-config-0 -- mongosh --eval "rs.status()"
kubectl exec -n dev mongo-shard-0 -- mongosh --eval "rs.status()"
kubectl exec -n test mongo-0 -- mongosh --eval "rs.status()"
```

### 3.4 Configuration Redis
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
  namespace: dev
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:7.2-alpine
        ports:
        - containerPort: 6379
```

### 3.5 Strat√©gie de Migration
```bash
./refresh-test-db.sh
curl -X POST http://demo.local/api/run-migration
```

### 3.6 Persistent Volumes
```bash
kubectl get pvc -A
kubectl get pv
```

---

## 4. üìä Monitoring et Scaling

### 4.1 Kubernetes Dashboard
```bash
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml
kubectl apply -f manifests/dashboard-admin.yaml
kubectl proxy
```

### 4.2 Metrics Server
```bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
kubectl -n kube-system patch deployment metrics-server --type='json' -p='[{"op": "add", "path": "/spec/template/spec/containers/0/args/-", "value": "--kubelet-insecure-tls"}]'
kubectl top pods -A
kubectl top nodes
```

### 4.3 Commandes de Monitoring
```bash
kubectl get pods -A -w
kubectl top pods -A
kubectl logs -n dev -l app=demo-app --tail=20
kubectl logs -f deployment/demo-app -n dev
kubectl get events -A --sort-by='.lastTimestamp'
kubectl get deployments -A
```

### 4.4 Scaling Manuel
```bash
kubectl scale deployment/demo-app --replicas=5 -n dev
kubectl scale deployment/demo-app --replicas=3 -n test
kubectl get pods -n dev
kubectl get pods -n test
kubectl rollout status deployment/demo-app -n dev
```
Ou bien juste allez sur le dashboard Kubernetes et mettre √† l'√©chelle les r√©plicas qu'on souhaite scaller.

---

## 5. üë®‚Äçüíª Guide d'Onboarding

### 5.1 Installation Express (10 minutes)
```bash
git clone <repository-url>
cd Project_DistributedSystems
# Configurer hosts
./start-cluster.sh
kubectl get all -n dev
kubectl get all -n test
```

### 5.2 Environnements Disponibles
| Environnement | URL | Usage | Architecture DB | Auto-Update |
|---------------|-----|-------|-----------------|-------------|
| DEV (Prod)         | demo.local | Production | Sharding MongoDB | Non |
| TEST          | test.demo.local | Tests | R√©plication MongoDB | Oui (5 min) |

### 5.3 Workflow de D√©veloppement
```bash
git checkout -b feature/ma-nouvelle-feature
# D√©velopper, tester
pytest -v
docker build -t demo-app:latest .
docker run -p 5000:5000 demo-app:latest
git add .
git commit -m "feat: description de la fonctionnalit√©"
git push origin feature/ma-nouvelle-feature
```

### 5.4 Commandes de D√©veloppement Quotidiennes
```bash
docker build -t <username>/demo-app:v2 .
docker run -p 5000:5000 <username>/demo-app:v2
kubectl set image deployment/demo-app demo-app=<username>/demo-app:v2 -n dev
kubectl rollout restart deployment/demo-app -n dev
```

### 5.5 Endpoints API Disponibles
- GET /  
- GET /user-dashboard  
- GET /api/stats  
- GET /api/users  
- GET /api/orders  
- POST /api/load-sample-data  
- POST /api/random-user  
- POST /api/random-order  
- POST /api/run-migration  
- DELETE /api/clear-data  
- GET /cache/status  
- POST /cache/clear  
- GET /sharding-info  

### 5.6 R√©solution de Probl√®mes Courants
- Application inaccessible : v√©rifier pods, services, ingress, logs, restart
- MongoDB inaccessible : reconfigurer sharding, logs, test ping
- Donn√©es corrompues : refresh TEST depuis DEV, reload sample, clear data
- Cache Redis non fonctionnel : v√©rifier, clear, status

### 5.7 D√©pannage Rapide
```bash
./start-cluster.sh
./setup-sharding.sh
./refresh-test-db.sh
kubectl rollout restart deployment/demo-app -n dev
kubectl rollout restart deployment/demo-app -n test
```

"""

